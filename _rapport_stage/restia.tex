\chapter{l'api de prédiction}
La brique du chatbot étant fini, reste la partie Machine Learning, j'ai décidé de séparer le chatbot des programmes d'intelligence artificielle et de placer tous les programmes dans une API qui est obtenable via requêtes \textit{REST}, ainsi, l'implémentation du projet se fait beaucoup plus facilement, d'un coté tous les programmes de prédictions et de l'autre le chatbot.\\
Les requêtes à l'api de Machine Learning se fait dans les Actions du chatbot.\\
\linebreak
Pour aboutir à un chatbot qui répond plutôt bien aux attentes des utilisateurs, nous devons extraire la nature du problème ($nature\_probleme$) les équipements concernés (comme les murs, fenêtres, grillage) ($equipement$) et les demandes techniques (une réclamation, renseignement, incident)  ($demande\_technique$).

\pagebreak
\section{Les ontologies}
Une ontologie est un ensemble de concepts qui donnent un sens à un groupe de mots, dans le chapitre précédant lors de l'introduction des slots, il y a eu une petite notion d'ontologie, dans le fait que pour une phrase on extrait des mots pour les associer à des slots.\\
Mais l'implémentation de la déduction des variables demandées ($nature\_probleme$, $equipement$ et $demande\_technique$) est plus complexe. Pour un corpus de mots construits à partir de huit Gigabit de données clients et de quelques programmes d'automatisation de l'extraction et d'analyse fait par nous-même, nous avons pu construire les corpus comme suit:
\ \linebreak
\begin{lstlisting}
Mots_Clef_Demande_technique.csv

Clef,Synonyme
adaptation,"adaptation,adaptations,adapter,adapte,ajustement,ajustements,ajuster,..."
effraction,"effraction,pillage,piller,pille,vol ,voller,voleur,vol avec effraction, ..."
epave,"epave,epave,epaves,delabre,delabrer,ruine,debris, ..."
deratisation,"deratisation,deratisation,presence de rat,des rats"
...
\end{lstlisting}
\ \linebreak
Pour chaque mots dans les synonymes, on lui associe sa clef, ce qui donne par un exemple:
\ \linebreak
\begin{lstlisting}
str = "Il y a une epave de voiture qui est devant une maison abandonne depuis longtemps, ce matin des rats sont venue m'attaquer."
print(ontologies(demande_technique, str)
> ["epave", "deratisation"]
\end{lstlisting}
\ \linebreak

Nous avons résumé en ontologie la phrase donnée pour en obtenir une série de mot clefs, ainsi coupler avec un algorithme d'apprentissage travaillant sur les chaînes de caractères, comme un réseau bayésiens naïf nous obtenons le type de $demande\_technique$ associé à la phrase posé ci-dessus:

\pagebreak

\begin{lstlisting}
Demande_technique_train.csv

Class,Input
adaptation,"[adaptation]"
amenagement,"[voirie]"
maintenance,"[maintenance,reclamation]"
incident,"[degradation,garantie]"
reclamation,"[change,degradation,reclamation]"
occupation_vide,"[epave]"
\end{lstlisting}

Nous comptons respectivement pour les trois ontologies ($nature\_probleme$, $equipement$ et $demande\_technique$), au moins deux cents synonymes (par fichier) pour respectivement 30, 52 et 23 clefs pour les fichiers des mots clefs et respectivement 975, 1242 et 156 lignes d'apprentissage pour l'algorithme de réseau bayésiens naïf.\\
A l'aide d'un de nos programmes, nous avons pu faire un estimateur sur le pouvoir de notre ontologie, nous avons semi automatisé la classification des huit Gigabit de transcrits et nous avons appelé l'entièreté des phrases utilises (donc des phrases autre que "oui","bonjour", "au revoir"...) sur notre api, les résultats pour $demande\_technique$ ne sont pas mauvais

\begin{lstlisting}
comportement_invervenant: OK:    0 | NOK:    0 | TOTAL:    0 | RATIO:0.00000
                        securiter: OK:    1 | NOK:    1 | TOTAL:    2 | RATIO:0.50000
                  contestation: OK:  127 | NOK:   85 | TOTAL:  212 | RATIO:0.59906
                amenagement: OK:  373 | NOK:  154 | TOTAL:  527 | RATIO:0.70778
                    abandonne: OK:   68 | NOK:   27 | TOTAL:   95 | RATIO:0.71579
                 maintenance: OK:  130 | NOK:   42 | TOTAL:  172 | RATIO:0.75581
                  reclamation: OK: 2126 | NOK:  678 | TOTAL: 2804 | RATIO:0.75820
                     adaptation: OK:   70 | NOK:   12 | TOTAL:   82 | RATIO:0.85366
             eclairage_collectif: OK:   51 | NOK:    8 | TOTAL:   59 | RATIO:0.86441
                            epave: OK:   14 | NOK:    2 | TOTAL:   16 | RATIO:0.87500
                       effraction: OK:   27 | NOK:    3 | TOTAL:   30 | RATIO:0.90000
                           voirie: OK:  411 | NOK:   35 | TOTAL:  446 | RATIO:0.92152
                   intervention: OK:  743 | NOK:   55 | TOTAL:  798 | RATIO:0.93108
                    degradation: OK:  282 | NOK:    8 | TOTAL:  290 | RATIO:0.97241
                    information: OK: 4999 | NOK:  107 | TOTAL: 5106 | RATIO:0.97904
                          change: OK:  691 | NOK:   10 | TOTAL:  701 | RATIO:0.98573
                        garantie: OK:  530 | NOK:    7 | TOTAL:  537 | RATIO:0.98696
                        incident: OK:  403 | NOK:    3 | TOTAL:  406 | RATIO:0.99261
                deinsectisation: OK:    1 | NOK:    0 | TOTAL:    1 | RATIO:1.00000
                     non_resolu: OK:    2 | NOK:    0 | TOTAL:    2 | RATIO:1.00000
                   amelioration: OK:   21 | NOK:    0 | TOTAL:   21 | RATIO:1.00000
                            squat: OK:    5 | NOK:    0 | TOTAL:    5 | RATIO:1.00000
                   deratisation: OK:   16 | NOK:    0 | TOTAL:   16 | RATIO:1.00000
\end{lstlisting}
\pagebreak

\section{Les algorithmes annexes}

Dans notre API, je viens d'expliquer la brique la plus importante, mais je voudrais aussi évoquer les autres \textit{end-points} qui ont leurs intérêts dans la construction du projet:

\begin{description}
\item[Normalizer]: traitent toutes chaînes avant tokenisation en enlevant les url, les caractères spéciaux, les accents et les majuscules.
\item[Tokenizer]: Qui pour un corpus de mots clefs, (voir un exemple ci-dessus) transforme la phrase précédemment normalisé en un ensemble de mots clefs
\item[un\_une]: qui pour un mot, donne sont genre ("un" ou "une"), utilisant un algorithme de réseau bayésiens naïf.
\item[un\_des]: qui pour un mot, prédit son article (du,de la,des,l') afin de construire des phrases le plus humainement compréhensible.
\item[astreinte]: qui pour un motif, un équipement et une nature problème précédemment prédit va prédire si une astreinte est requit pour le problème.
\item[ner]: Qui pour une phrase du client retourne que la partie intéressante (voir dans la section NER au-dessus)
\formula{"J'ai une fuite dans ma salle de bain et mes enfants jouent dans le jardin"}
\formula{"une fuite dans ma salle de bain"}
\item[ner\_conjugate]: qui pour une phrase extraite depuis le NER va changer les mots donnant l’impression que le bot répond normalement à une phrase:
\formula{"une fuite dans ma salle de bain"}
\formula{"votre fuite dans votre salle de bain"}
\item[pos\_neg]: qui pour une réponse donnée sous forme d'une phrase, prédit si la réponse est positif ou négatif.
\end{description}

